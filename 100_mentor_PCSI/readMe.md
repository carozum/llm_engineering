# MVP Mentor Pr√©pa PC

‚úÖ Une collection globale + m√©tadonn√©es riches (subject, year, chapters).

‚úÖ Recherche en cascade : avec filtres.

‚úÖ UI claire : S√©lecteur de sujet/ann√©e/chapitres + visibilit√© √† l‚Äôupload.

‚úÖ Extensible : facile de transf√©rer √† un ‚Äúutilisateur √©conomie‚Äù demain, sans casser le reste.

## Technos
Streamlit --> bootstrap, python, Chroma --> QDrant, SQLite3 --> postGres

| Option                              | Quand l‚Äôutiliser                                | Avantages                                           | Limites                                                              |
| ----------------------------------- | ----------------------------------------------- | --------------------------------------------------- | -------------------------------------------------------------------- |
| **Streamlit**                       | Prototyper tr√®s vite, local, un seul fichier    | Ultra-rapide, composant chat natif, state simple    | Moins flexible pour une UX tr√®s custom / multi-pages ‚Äúproduit‚Äù |
| **Gradio**                          | D√©mos IA simples, notebooks                     | Upload/preview simples, hosting facile (Spaces)     | UX moins ‚Äúapp‚Äù, styling limit√©                                       |
| **FastAPI + Jinja2/HTMX/Bootstrap** | **Produit long terme**, contr√¥le fin, auth, SEO | Total contr√¥le, propre en prod, facile √† dockeriser | Demande plus de code (forms, state, websockets si live stream)       |



## Mod√®les 
- OpenAI
- Antrhopic
- Gemini

==> TODO Ajouter Deepseek

## Lancer

pip install -r requirements.txt

streamlit run app.py


## Feuille de route

‚úÖ MVP 1 --- Streamlit (ci-dessus) : multiturn + choix mod√®le.

    ‚ûï ajouter deepSeek comme mod√®le

    ‚ûï Multi-mod√®les par sujet : p.ex. maths/physique ‚Üí mod√®le de raisonnement fort ; √©co/droit ‚Üí mod√®le plus verbeux/structur√© (r√©f√©rences, d√©finitions). On peut router par subject c√¥t√© code (s√©lection du model=).

‚úÖ MVP 1.1 Upload + tags (ci-dessus).
==> TODO ajouter d'autres types de documents docx...

‚úÖ MVP 1.2 Possibilit√© de supprimer des documents upload√©s

‚ûï  RAG : 

    ‚úÖ avec ChromaDB et possibilit√© de choisir si utilis√© ou pas

    ==> indexation des images ? par g√©n√©ration d'un texte descriptif

    ==> service QDRANT pour remplacer Chroma ?
        Chroma (MVP) : OK, g√®re where sur metadata ‚Üí parfait pour d√©marrere et pouvoir filtrer.
        Qdrant (niveau 2) : filtres payload puissants, perf et scale meilleurs.
        
        Qdrant : qu‚Äôest-ce que √ßa apporte vs Chroma ?
        En bref : Qdrant = moteur vecteur serveur (hautement fiable + filtres puissants), Chroma = lib Python pratique (MVP local).
        Avantages Qdrant concrets :
        - Filtres/Payloads puissants : must/should/must_not, filtres sur listes (overlap), range, bool, etc.
        - Index de payload (acc√©l√®re les filtres), snapshots & backups natifs.
        - Multi-collections, named vectors (plusieurs embeddings par doc : denses/sparses/hybrides).
        - Perf & scale : HNSW optimis√©, quantization (SQ, PQ), shard/replica en √©dition distribu√©e.
        - APIs REST/gRPC + clients officiels (Python/JS/Rust), int√©gration facile en prod (Docker/K8s).
        - Hybrid search (BM25+sparse+dense) avec les features r√©centes.

        üëâ Si on veut multi-utilisateurs, multi-sujets avec filtres (subject, year, chapters, visibility, owner), Qdrant est nettement plus robuste.

    ==> pdf pas de lecture des images ?

    ==> visualisation des sources 

    ==> reranker open-source: Cohere Rerank, bge-reranker, ou un petit cross-encoder local

‚ûï Vision (photo d‚Äô√©nonc√©s) : ajoute vision_parse() (Claude/GPT/Gemini).
    OCR de formules : si jamais la vision LLM patine, ajoute Mathpix pour LaTeX robuste.

‚ûï Agents : LangGraph dans le backend FastAPI (router ‚Üí retrieve ‚Üí solve ‚Üí critic). fichier graph.py (LangGraph minimal)
    LangGraph pour l‚Äôorchestration multi-agents :
    - RouterAgent (d√©tecte le sujet + mode),
    - TutorAgent (Socratique / solution),
    - outils : retrieve(), vision_parse(), sympy_solve(), unit_check(), critic().

‚ûï Authentification ou d√©ployer des images diff√©rentes pour les diff√©rents utilisateur (version assistant personnel)

‚ûï Passer √† des routes / microservices FASTAPI, me le conseille tu ? pour le moment, monolithique. 

‚ûï Est ce que Streamlit peut √™tre utilis√© en prod ?? assez fiable ??

‚ûï anki : export .csv (Question;R√©ponse;Tag) depuis les √©changes tagg√©s ‚Äú√Ä r√©viser‚Äù.

‚ûï garder la trace des erreurs courantes

‚ûï Sauvegarde des fichiers sur un cloud

‚ûï Uploader directement dans la question sans que √ß√† entre dans le RAG

‚ûï personnalisation utilisateur (r√©sum√© d'une conversation) -- o√π sauvegarder ? 
    M√©moire ‚Äúprofil‚Äù (pr√©f√©rences & lacunes) : table user_profiles + injection dans le prompt syst√®me √† chaque tour + user_stats.
    Cr√©e une table user_profiles et mets un middleware qui injecte un r√©sum√© dans le system prompt √† chaque tour.
   
    O√π enregistrer ‚Äúce que l‚Äôutilisateur aime‚Äù ?
    - Profil (pr√©f√©rences explicites : format, mode, rythme).
    - Historique agr√©g√© (tags rencontr√©s + erreurs fr√©quentes).
    - Exemple : table user_stats(user_id, tag, seen_count, error_count, last_seen_at) mise √† jour apr√®s chaque tour.
    - √áa alimente :
        - un pr√©-prompt (rappeler m√©thodes adapt√©es),
        - un plan de r√©vision (g√©n√©rer des cartes Anki cibl√©es).

    Auto-mise √† jour : apr√®s chaque tour, tagge les sujets d√©tect√©s (LLM ou simple regex sur la r√©ponse) et incr√©mente les compteurs d‚Äôerreurs r√©currentes (ex. signe, d√©rivation produit, unit√©s).
    

‚ûï Voir les conversations anciennes. DB Postgres ou SQLite3 ?

‚ûï Back Fast API : un /retrieve, un /chat... main.py complet (endpoints /chat, /upload, /docs)

    FastAPI pour exposer :
    - POST /chat (multimodal, multi-provider),
    - POST /upload (stockage + metadata),
    - GET /docs (liste filtr√©e),
    - POST /retrieve (RAG).

    backend/
        main.py              # FastAPI (endpoints)
        graph.py             # LangGraph (route -> retrieve -> solve -> critic)
        llm_clients.py       # OpenAI/Anthropic/Gemini wrappers
        storage/
            uploads/           # fichiers
            index.db           # SQLite (docs, tags, users)
        rag/
            qdrant_adapter.py  # plus tard


‚ûï en prod
    ==> VM : Docker + Caddy (HTTPS) ‚Äî tu auras d√©j√† la s√©paration front/back.
    ==> plus un docker-compose pr√™t pour la VM.



-------------------------------------------------------------------------------------------------------------------------------------------------

# Version ‚ÄúAgent‚Äù : qu‚Äôest-ce qui change ?

## 1) Architecture recommand√©e

Un **RouterAgent** (d√©termine le sujet + le mode : socratique vs solution, ‚Äúavec RAG‚Äù vs ‚Äúpur raisonnement‚Äù).

Des **Outils** (plut√¥t que ‚Äúun agent par mati√®re‚Äù rigide) :
- retrieve(subject, year, chapters) ‚Üí interroge le vector store (Chroma/Qdrant).
- vision_parse() ‚Üí lit une photo/scan et renvoie LaTeX + texte structur√©.
- math_solve() ‚Üí essai SymPy pour calculs symboliques (int√©grales, d√©riv√©es, syst√®mes).
- unit_check() ‚Üí v√©rifie coh√©rence d‚Äôunit√©s.
- critic() ‚Üí relit la solution et signale erreurs/omissions.

Un **TutorAgent** (LLM) qui planifie : comprendre ‚Üí d√©composer ‚Üí appeler les outils ‚Üí expliquer ‚Üí v√©rifier ‚Üí citer.

Pourquoi pas ‚Äúun agent par mati√®re‚Äù ?
Possible, mais en pratique un router + un tuteur unique avec des outils sp√©cialis√©s est plus simple √† maintenir et r√©utiliser. Si un jour l‚Äô√©conomie/droit n√©cessitent des r√®gles vraiment diff√©rentes, tu ajoutes un SubjectPolicyAgent (politiques par mati√®re) que le Router appelle.

## 2) Squelette minimal avec LangGraph (id√©e)

```
# pip install langgraph langchain openai qdrant-client sympy
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, List, Dict, Any

class S(TypedDict):
    query: str
    subject: str
    context: List[Dict]   # passages RAG
    plan: str
    answer: str

def route_subject(s: S) -> str:
    # soit lire le dropdown UI, soit classer via LLM
    return "retrieve" if s["subject"] in {"maths","physique","economie","droit"} else "solve"

def retrieve_node(s: S) -> S:
    s["context"] = retrieve(subject=s["subject"], query=s["query"])  # ton wrapper
    s["plan"] = "d√©composer en √©tapes avec sources"
    return s

def solve_node(s: S) -> S:
    s["answer"] = tutor_llm(query=s["query"], context=s["context"])  # ton prompt syst√®me socratique
    return s

def critic_node(s: S) -> S:
    s["answer"] = critic_llm(s["answer"])  # contr√¥le coh√©rence + unit√©s + citations
    return s

g = StateGraph(S)
g.add_node("retrieve", retrieve_node)
g.add_node("solve", solve_node)
g.add_node("critic", critic_node)
g.add_edge(START, route_subject)
g.add_edge("retrieve", "solve")
g.add_edge("solve", "critic")
g.add_edge("critic", END)
app = g.compile()
```

B√©n√©fices : tra√ßabilit√© des √©tapes, facile d‚Äôins√©rer un vision_parse ou un math_solve(sympy) √† un endroit pr√©cis.










QUESTIONS POUR GPT


if st.sidebar.button("Uploader") and file is not None:
    fid = uuid.uuid4().hex
    ext = pathlib.Path(file.name).suffix.lower()
    out = DATA_DIR / f"{fid}{ext}"
    out.write_bytes(file.read())
    entry = {
        "id": fid,
        "name": file.name,
        "path": str(out),
        "subject": subject,
        "year": year,
        "chapters": [c.strip() for c in chapters.split(",") if c.strip()],
        "kind": "pdf" if ext==".pdf" else "image"
    }
    idx = load_index()
    idx.append(entry)
    save_index(idx)
    st.sidebar.success(f"Fichier enregistr√© : {file.name}")

    # Indexation RAG si PDF
    if entry["kind"] == "pdf":
        try:
            index_file_to_chroma(entry)
            st.sidebar.info("Index√© dans le moteur de recherche (RAG).")
        except Exception as e:
            st.sidebar.warning(f"Indexation partielle: {e}")
    
    if entry["kind"] == "image":
        texte = describe_image_with_llm(entry)

COmment j'adapte pour l'image ? √Ä l‚Äôupload, si kind == "image", tu appelles  describe_image_with_llm, puis tu fais un col.add avec le texte et des m√©tadonn√©es (page_start/page_end peuvent √™tre None).

--------------------------------------------------------------------------------------------------------------------------

(c) Vision (photo d‚Äô√©nonc√©)
Ajoute un bouton ‚ÄúAnalyser une image‚Äù : on reformule en texte + LaTeX + on propose une strat√©gie. Tu as d√©j√† la fonction describe_image_with_llm.

Tu peux d√©crire. 

----------------------------------------------------------------------------------------------

(d) Agents (LangGraph) + FastAPI
Oui, je te conseille de garder Streamlit pour l‚ÄôUI mais d‚Äôextraire la logique vers un backend FastAPI quand tu ajoutes les agents et Qdrant.

LangGraph = orchestration claire : route ‚Üí retrieve ‚Üí solve ‚Üí critic.

Tu pourras appeler /chat depuis Streamlit.

Si tu veux, je te file un graph.py minimal + main.py FastAPI au prochain pas ‚Äî mais tu as d√©j√† beaucoup ici, restons focus.